import csv
import re
import jsonlines
import psutil
import pandas as pd
from tqdm import tqdm
from transformers import AutoTokenizer

# ---------- âœ… é…ç½®åŒº ----------
CONTAIN_HISTORY = False  # æ˜¯å¦åŒ…å«å†å²è®°å½•
CHUNK_SIZE = 50000  # æ¯æ‰¹å†™å…¥è¡Œæ•°

# Tokenizer å’Œæ•°æ®è·¯å¾„é…ç½®
TOKENIZER_PATH = './model/mateconv_tokenizer'

# æŒ‡å®šç›®æ ‡æ•°é‡ï¼ˆåŸºäºä¼°ç®—ï¼Œä¸€æ¡æ ·æœ¬çº¦ 2~3KBï¼‰
CHINESE_TARGET_COUNT = 6_000_000  # å¤§çº¦1/2
ENGLISH_TARGET_COUNT = 950_000  # å¤§çº¦1/3

CHINESE_JSONL_PATH = './deepctrl-sft-data/sft_data_zh.jsonl'
ENGLISH_JSONL_PATH = './deepctrl-sft-data/sft_data_en.jsonl'

# è¾“å‡ºè·¯å¾„é…ç½®
OUTPUT_DIR = './data'
OUTPUT_FILENAME = 'sft_data_mixed.csv' if CONTAIN_HISTORY else 'sft_data_mixed_single.csv'
OUTPUT_PATH = f'{OUTPUT_DIR}/{OUTPUT_FILENAME}'

# ---------- ğŸ” åŠ è½½åˆ†è¯å™¨ ----------
tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, use_fast=False)
print('âœ… tokenizerè¯è¡¨å¤§å°ï¼š', len(tokenizer))


def log_memory_usage():
    """æ‰“å°å†…å­˜ä½¿ç”¨æƒ…å†µã€‚"""
    mem = psutil.virtual_memory()
    print(f"[MEMORY] Used: {mem.used / 1e9:.2f} GB / {mem.total / 1e9:.2f} GB")


def chinese_ratio(text):
    """è®¡ç®—æ–‡æœ¬ä¸­ä¸­æ–‡å­—ç¬¦çš„æ¯”ä¾‹ã€‚"""
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    return len(chinese_chars) / len(text) if text else 0


def process_and_write_data(data, file_path):
    """å¤„ç†æ•°æ®å¹¶å†™å…¥ CSV æ–‡ä»¶ã€‚"""
    q_lst, a_lst, history_lst = [], [], []

    for per in data:
        history = per.get('history', '')
        q = (per.get('q') or '').strip()
        a = (per.get('a') or '').strip()

        # è¿‡æ»¤æ— æ•ˆæ•°æ®
        if (CONTAIN_HISTORY and (not history or len(history) == 0)) or not q or not a:
            continue
        if len(q) < 10 or len(a) < 5:
            continue
        if len(q) > 256 or len(a) > 256:
            continue
        if not (chinese_ratio(q) > 0.9 and chinese_ratio(a) > 0.9) and 'zh' in file_path:
            continue
        if not (chinese_ratio(q) < 0.1 and chinese_ratio(a) < 0.1) and 'en' in file_path:
            continue

        q_lst.append(q)
        a_lst.append(a)
        history_lst.append(history if CONTAIN_HISTORY else [])

    # åˆ›å»ºå¹¶å†™å…¥ DataFrame
    df = pd.DataFrame({'history': history_lst, 'q': q_lst, 'a': a_lst})
    df.to_csv(file_path, mode='a', header=False, index=False,
              lineterminator='\r\n', escapechar='\\', quoting=csv.QUOTE_MINIMAL)


def sft_process():
    """æŒ‰æ¯”ä¾‹æŠ½æ ·ä¸­æ–‡å’Œè‹±æ–‡ JSONL æ–‡ä»¶ï¼Œæ¸…æ´—å¹¶å†™å…¥åˆå¹¶ CSVã€‚"""
    data_sources = [
        {"path": CHINESE_JSONL_PATH, "target_count": CHINESE_TARGET_COUNT},
        {"path": ENGLISH_JSONL_PATH, "target_count": ENGLISH_TARGET_COUNT}
    ]

    # åˆ›å»º CSV å¹¶å†™å…¥è¡¨å¤´
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        f.write('history,q,a\n')

    for src in data_sources:

        with open(src['path'], 'r', encoding='utf-8') as f:
            total_lines = sum(1 for _ in f)
        
        selected = 0
        valid_buffer = []

        print(f"ğŸ“‚ å¼€å§‹å¤„ç†æ–‡ä»¶ï¼š{src['path']}ï¼Œç›®æ ‡æŠ½å– {src['target_count']} æ¡")
        with jsonlines.open(src['path']) as reader:
            for obj in tqdm(reader, desc=f"Sampling from {src['path']}",total=total_lines):
                q = (obj.get('input') or '') + (obj.get('q') or '')
                a = (obj.get('output') or '') + (obj.get('a') or '')
                history = obj.get('history', '')

                # æ¸…æ´—é€»è¾‘ - åªè¦æ»¡è¶³ä¸‹åˆ—ä»»ä½•æ¡ä»¶ï¼Œå°±ä¸ä¿ç•™è¿™æ¡æ ·æœ¬
                if (CONTAIN_HISTORY and (not history or len(history) == 0)) or not q or not a:
                    continue
                if len(q) < 10 or len(a) < 5 or len(q) > 512 or len(a) > 512:
                    continue
                if not (chinese_ratio(q) > 0.7 and chinese_ratio(a) > 0.7) and 'zh' in src['path']:
                    continue
                if not (chinese_ratio(q) < 0.1 and chinese_ratio(a) < 0.1) and 'en' in src['path']:
                    continue

                valid_buffer.append({'history': history if CONTAIN_HISTORY else [], 'q': q, 'a': a})
                selected += 1

                if len(valid_buffer) >= CHUNK_SIZE:
                    process_and_write_data(valid_buffer, OUTPUT_PATH)
                    valid_buffer = []

                if selected >= src['target_count']:
                    break

            if valid_buffer:
                process_and_write_data(valid_buffer, OUTPUT_PATH)

        print(f"âœ… å®Œæˆï¼š{src['path']} å®é™…é‡‡æ ·ï¼š{selected} æ¡")

    log_memory_usage()
    print("ğŸ‰ æ•°æ®æŠ½æ ·ä¸å†™å…¥å®Œæˆï¼")

if __name__ == "__main__":
    sft_process()