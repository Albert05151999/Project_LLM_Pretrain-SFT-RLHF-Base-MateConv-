# ğŸ§  MateConv å°æ¨¡å‹é¢„è®­ç»ƒ - SFT - RLHF é¡¹ç›®

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)]()
[![Framework](https://img.shields.io/badge/DeepSpeed-Enabled-orange.svg)]()
[![WandB](https://img.shields.io/badge/Tracking-W%26B-yellow.svg)]()

---

## ğŸ“˜ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ—¨åœ¨ç ”ç©¶ **å°è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆâ‰ˆ0.1B å‚æ•°ï¼‰** åœ¨ä½¿ç”¨ **Mixture of Experts (MoE)** æ¶æ„ä¸‹çš„è¡¨ç°ï¼Œ
å¹¶ä¸ä¼ ç»Ÿ **Feed-Forward Network (FFN)** æ¶æ„è¿›è¡Œå¯¹æ¯”ï¼ŒéªŒè¯ MoE æ¶æ„åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šçš„æ½œåœ¨ä¼˜åŠ¿ã€‚

ç ”ç©¶ç›®æ ‡åŒ…æ‹¬ï¼š

- è·‘é€š **Pretrain â†’ SFT â†’ DPO** çš„å®Œæ•´è®­ç»ƒæµç¨‹ï¼›  
- è§‚å¯Ÿ MoE ä¸ FFN åœ¨ç”Ÿæˆè´¨é‡ä¸è´Ÿè½½å‡è¡¡ä¸Šçš„å·®å¼‚ï¼›  
- æ¢è®¨å°æ¨¡å‹åœ¨ DPO ä¸‹çš„ **ç¾éš¾æ€§é—å¿˜ (Catastrophic Forgetting)** ç°è±¡ã€‚

> æ¨¡å‹åŸºç¡€ï¼š`MateConv-0.02B`ï¼ˆLLaMA æ¶æ„ã€RoPE ä½ç½®ç¼–ç ã€RMSNormã€KV-Cache æ¨ç†ä¼˜åŒ–ï¼‰  
> æ”¹é€ åå¯ç”¨ **DeepSeek é£æ ¼ MoE å¹¶è¡Œ FFN å±‚**ï¼Œæ•´ä½“è§„æ¨¡çº¦ä¸º **0.1B å‚æ•°**ã€‚

---

## ğŸ§© æ•°æ®ä¸æ¨¡å‹é…ç½®

| é˜¶æ®µ | ä½¿ç”¨æ•°æ®é›† | æ¥æº |
|------|-------------|------|
| Tokenizer | HuggingFace å¼€æºå°è¯è¡¨ï¼ˆ6400è¯ï¼‰ | HuggingFace |
| é¢„è®­ç»ƒ (Pretrain) | ä¸­æ–‡é€šç”¨è¯­æ–™ï¼ˆ31GBï¼‰ | [åºåˆ—çŒ´å­å¼€æºæ•°æ®é›†](https://github.com/mobvoi/seq-monkey-data/blob/main/docs/pretrain_open_corpus.md) |
| SFT å¾®è°ƒ | åŒ æ•°ç§‘æŠ€ DeepCtrl SFT æ•°æ®é›† | [ModelScope: deepctrl-sft-data](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data/files) |
| RLHF / DPO | ç”± GPT-4o è‡ªåŠ¨ç”Ÿæˆåå¥½å¯¹ (æ­£/åæ ·æœ¬) | é€šè¿‡ `7.gen_prefs_openai.py` è‡ªåŠ¨ç”Ÿæˆ |

---

## âš™ï¸ ç¯å¢ƒé…ç½®

### 1ï¸âƒ£ åŸºç¡€ç¯å¢ƒ
```bash
pip install -r requirements.txt
```

éœ€åŒ…å«ï¼š
- `torch`, `transformers`, `deepspeed`, `wandb`, `tqdm`, `datasets`
- Linux GPU ç¯å¢ƒï¼ˆæ¨è 2 å¼ æ˜¾å¡ï¼‰

### 2ï¸âƒ£ WandB ç¯å¢ƒå˜é‡
```bash
export WANDB_API_KEY="ä½ çš„_API_KEY"
export WANDB_PROJECT="MateConv_MoE"
```

---

## ğŸ—‚ï¸ æ•°æ®ä¸‹è½½

### âœ… å°æ•°æ®é›†ï¼ˆç™¾åº¦ç½‘ç›˜ï¼‰
```bash
./BaiduPCS-Go login -bduss=ä½ çš„bduss
./BaiduPCS-Go cd /path/to/data
nohup ./BaiduPCS-Go d "/path/to/data" -saveto /root/dataset > /root/bpcs.log 2>&1 &
tail -f /root/bpcs.log
```

### âœ… å¤§æ•°æ®é›†ï¼ˆæ¨èæ–¹å¼ï¼‰
ä½¿ç”¨ `hfd + aria2c + git-lfs` ä¸‹è½½ã€‚

---

## ğŸ”§ æ•°æ®é¢„å¤„ç†ï¼ˆNotebookï¼‰

1ï¸âƒ£ `1.Tokenizer_Training.ipynb` â€” tokenizer è®­ç»ƒ  
2ï¸âƒ£ `2.Prepare_Train_Data.ipynb` â€” æ•°æ®æ¸…æ´—ä¸æ ¼å¼åŒ–  
3ï¸âƒ£ `3.pretrain.py` â€” é¢„è®­ç»ƒæ•°æ®åŠ è½½ä¸æ„å»º  

åå°è¿è¡Œï¼š
```bash
nohup jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root > jlab.log 2>&1 &
tail -f jlab.log
```

---

## ğŸš€ è®­ç»ƒæµç¨‹

### ğŸ§± (1) é¢„è®­ç»ƒ Pretrain
```bash
mkdir -p logs
nohup deepspeed --master_port 29500 --num_gpus=2 4.pretrain.py --epochs 15   > logs/train.log 2>&1 & echo $! > train.pid
tail -f logs/train.log
```

åœæ­¢è®­ç»ƒï¼š
```bash
kill -2 $(ps -o pgid= -p $(cat train.pid) | tr -d ' ')
```

---

### ğŸ§© (2) SFT å…¨é‡å¾®è°ƒ
```bash
mkdir -p logs
CUDA_VISIBLE_DEVICES=0,1 MASTER_ADDR=127.0.0.1 MASTER_PORT=29500 nohup deepspeed --num_gpus=2 5.full_sft.py --out_dir out --epochs 5   > logs/sft.log 2>&1 & echo $! > sft.pid
tail -f logs/sft.log
```

---

## ğŸ“Š WandB ç›‘æ§ MoE è´Ÿè½½å‡è¡¡

### é¢„è®­ç»ƒé˜¶æ®µ
```bash
export WANDB_PROJECT="MateConv_MoE-pretrain"
nohup deepspeed --master_port 29500 --num_gpus=2 4.pretrain.py   --epochs 15 --use_wandb --wandb_project "$WANDB_PROJECT"   > logs/pretrain.log 2>&1 & echo $! > pretrain.pid
```

### SFT é˜¶æ®µ
```bash
export WANDB_PROJECT="MateConv_MoE-sft"
nohup deepspeed --master_port 29500 --num_gpus=2 5.full_sft.py   --out_dir out --epochs 5 --use_wandb --wandb_project "$WANDB_PROJECT"   > logs/sft.log 2>&1 & echo $! > sft.pid
```

---

## ğŸ§¹ WandB ç¼“å­˜è‡ªåŠ¨æ¸…ç†ï¼ˆæ¯åŠå°æ—¶ï¼‰

```bash
mkdir -p /root/autodl-tmp
nohup bash -c '
while true; do
  date
  find "/root/.cache/wandb/artifacts" -type f -mmin +30 -delete || true
  find "/root/.cache/wandb/artifacts" -type d -empty -delete || true
  sleep 3600
done
' >> /root/autodl-tmp/wandb_clean.log 2>&1 &
```

æŸ¥çœ‹ï¼š
```bash
tail -f /root/autodl-tmp/wandb_clean.log
```

---

## ğŸ§® æ¨ç†ä¸è¯„ä¼°

åœ¨å®Œæˆ SFT åï¼Œå¯ä½¿ç”¨ï¼š
```bash
6.inference&evaluate.ipynb
```
è¯„ä¼°ä¸åŒæ¶æ„ï¼ˆMoE vs FFNï¼‰åœ¨ç”Ÿæˆè´¨é‡ä¸Šçš„å·®å¼‚ã€‚

---

## ğŸ§© DPO è®­ç»ƒæµç¨‹

### å‚æ•°è®¾å®š
| é¡¹ç›® | å€¼ |
|------|----|
| ç”Ÿæˆæ¨¡å‹ | GPT-4o, temperature=0.7 |
| è¯„å®¡æ¨¡å‹ | GPT-4o-mini, temperature=0.0 |
| N_PROMPTS | 3000 |
| K_SAMPLES | 4 |
| Î² | 0.2 |
| KL ç³»æ•° | 0.05 |

### æ•°æ®ç”Ÿæˆ
```bash
export OPENAI_API_KEY="ä½ çš„_API_KEY"
nohup python 7.gen_prefs_openai.py > logs/gen_prefs.log 2>&1 & echo $! > gen_prefs.pid
tail -f logs/gen_prefs.log
```

### DPO è®­ç»ƒ
```bash
export WANDB_PROJECT="MateConv_DPO"
export WANDB_API_KEY="ä½ çš„_API_KEY"
nohup deepspeed --master_port 29500 --num_gpus=2 9.train_dpo.py   --out_dir out_dpo   --pairs_path ./dataset/dpo_pairs.jsonl   --epochs 20 --max_steps 1800 --batch_size 16 --learning_rate 1e-4   --beta 0.2 --kl_coef 0.05 --warmup_ratio 0.06   --accumulation_steps 2 --grad_clip 1.0 --use_wandb   > logs/dpo_train.log 2>&1 & echo $! > dpo_train.pid
tail -f logs/dpo_train.log
```

---

## ğŸ“ˆ å®éªŒæ€»ç»“

- MoE æ¶æ„åœ¨å°æ¨¡å‹ä¸­è¡¨ç°å‡ºè½»å¾®ä½†ç¨³å®šçš„ç”Ÿæˆæå‡ï¼›
- DPO é˜¶æ®µåœ¨ 0.1B è§„æ¨¡ä¸‹å­˜åœ¨ç¾éš¾æ€§é—å¿˜é£é™©ï¼›
- WandB å¯æœ‰æ•ˆè§‚å¯Ÿå„ä¸ªä¸“å®¶ï¼ˆExpertsï¼‰çš„è´Ÿè½½å‡è¡¡æƒ…å†µï¼›
- æ•´ä½“æµç¨‹æˆåŠŸè·‘é€š Pretrain â†’ SFT â†’ DPO çš„ç«¯åˆ°ç«¯å®éªŒé“¾è·¯ã€‚

---

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº **MIT License** å¼€æºåè®®å‘å¸ƒã€‚  
å¦‚éœ€å¼•ç”¨æˆ–äºŒæ¬¡å¼€å‘ï¼Œè¯·æ³¨æ˜åŸå§‹ä»“åº“é“¾æ¥ï¼š

> ğŸ”— [Project_LLM_Pretrain-SFT-RLHF-Base-MateConv-](https://github.com/Albert05151999/Project_LLM_Pretrain-SFT-RLHF-Base-MateConv-.git)

---

## ğŸ§­ ä½œè€…ä¿¡æ¯

**Author:** Albert Lee  
**Institution:** National University of Singapore  
**Reference:** èµ‹èŒƒç©ºé—´ MateConvå¼€æº0.02Bä¸­æ–‡æ¨¡å‹ https://kq4b3vgg5b.feishu.cn/docx/R6aJdgo0mo2Tb1xBy05cEAcen9Y